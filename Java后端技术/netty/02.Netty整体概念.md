---
tags:
  - Netty
  - nio
---

##  Netty的概述

1. Netty是一个异步，基于事件驱动的的网络应用框架，用于快速开发可维护的高性能服务器和客户端。
2. Netty基于NIO实现，对jdk的NIO进行了进一步的封装，使用更加灵活
3. “快速和简单”并不意味着最终的应用程序将面临可维护性或性能问题。 Netty是根据从实现许多协议(如FTP、SMTP、HTTP和各种二进制和基于文本的遗留协议)中获得的经验精心设计出来的， 因此，Netty成功地找到了一种方法，在不妥协的情况下实现了简单的开发、性能、稳定性和灵活性。  

![Netty整体架构](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050134323.png)

### Core核心层

Core 核心层是 Netty 最精华的内容，它提供了底层网络通信的通用抽象和实现，包括可扩展的事件模型、通用的通信 API、支持零拷贝的 ByteBuf 等。

### Protocol Support 协议支持层

协议支持层基本上覆盖了主流协议的编解码实现，如 HTTP、SSL、Protobuf、压缩、大文件传输、WebSocket、文本、二进制等主流协议，此外 Netty 还支持自定义应用层协议。Netty 丰富的协议支持降低了用户的开发成本，基于 Netty 我们可以快速开发 HTTP、WebSocket 等服务。

### Transport Service 传输服务层

传输服务层提供了网络传输能力的定义和实现方法。它支持 Socket、HTTP 隧道、虚拟机管道等传输方式。Netty 对 TCP、UDP 等数据传输做了抽象和封装，用户可以更聚焦在业务逻辑实现上，而不必关系底层数据传输的细节。

## Netty为什么性能这么高呢

1. Netty作为异步事件驱动的网络，高性能之处主要来自于其I/O模型和线程处理模型，不同于传统BIO，客户端的连接以及事件处理都阻塞在同一个线程里，Netty则将客户端的线程和处理客户端的线程分离开来；（高效的Reactor线程模型）
2. Netty的IO线程NioEventLoop由于聚合了多路复用器Selector，可以同时并发处理成百上千个客户端连接；（IO多路复用模型）
3. Netty底层还实现了零拷贝，避免了IO过程中数据在操作系统底层来回”无效的“拷贝和系统态切换；（零拷贝）
4. 无锁串行化设计，串行设计：消息的处理尽可能在一个线程内完成，期间不进行线程切换，避免了多线程竞争和同步锁的使用；（单线程）
5. Netty 默认提供了对Google Protobuf 的支持，通过扩展Netty 的编解码接口，可以实现其它的高性能序列化框架（高性能的序列化框架）
6. Netty中大量使用了volatile，读写锁，CAS和原子类；（高效并发编程）
7. Netty的内存分配管理实现非常高效，Netty内存管理分为了池化（Pooled）和非池化（UnPooled），heap（堆内内存）和direct（堆外内存），对于Netty默认使用的是池化内存管理，其内部维护了一个内存池可以循环的创建ByteBuf（Netty底层实现的一个Buffer），提升了内存的使用效率，降低由于高负载导致的频繁GC。同时Netty底层实现了jemalloc算法（jemalloc3实现的满二叉树，读内存进行一个分隔、jemalloc4则优化了jemalloc3的算法，实现了将内存切割成了一个二维数组维护的一个数据结构，提升了内存的使用率）（Netty内存管理非常高效）

## Netty中的线程模型

![Netty线程模型](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050134707.png)

Netty线程模型流程分析

1. Netty 抽象出两组线程池 ，BossGroup 专门负责接收客户端的连接，WorkerGroup 专门负责网络的读写
2. BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup
3. NioEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是 NioEventLoop
4. NioEventLoop 表示一个不断循环的执行处理任务的线程，每个 NioEventLoop 都有一个 Selector，用于监听绑定在其上的 socket 的网络通讯
5. NioEventLoopGroup 可以有多个线程，即可以含有多个 NioEventLoop
6. 每个 BossGroup下面的NioEventLoop 循环执行的步骤有 3 步
   - 轮询 accept 事件
   - 处理 accept 事件，与 client 建立连接，生成 NioScocketChannel，并将其注册到某个 workerGroup NIOEventLoop 上的 Selector
   - 继续处理任务队列的任务，即 runAllTasks
7. 每个 WorkerGroup NIOEventLoop 循环执行的步骤
   - 轮询 read，write 事件
   - 处理 I/O 事件，即 read，write 事件，在对应 NioScocketChannel 处理
   - 处理任务队列的任务，即 runAllTasks
8. 每个 Worker NIOEventLoop 处理业务时，会使用 pipeline（管道），pipeline 中包含了 channel（通道），即通过 pipeline 可以获取到对应通道，管道中维护了很多的处理器



## Netty逻辑架构和启动流程

- 服务端启动初始化时有 Boss EventLoopGroup 和 Worker EventLoopGroup 两个组件，其中 Boss 负责监听网络连接事件。当有新的网络连接事件到达时，则将 Channel 注册到 Worker EventLoopGroup。
- Worker EventLoopGroup 会被分配一个 EventLoop 负责处理该 Channel 的读写事件。每个 EventLoop 都是单线程的，通过 Selector 进行事件循环。
- 当客户端发起 I/O 读写事件时，服务端 EventLoop 会进行数据的读取，然后通过 Pipeline 触发各种监听器进行数据的加工处理。
- 客户端数据会被传递到 ChannelPipeline 的第一个 ChannelInboundHandler 中，数据处理完成后，将加工完成的数据传递给下一个 ChannelInboundHandler。
- 当数据写回客户端时，会将处理结果在 ChannelPipeline 的 ChannelOutboundHandler 中传播，最后到达客户端。

![Netty的架构逻辑](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050134927.png)

### 网络通讯层

网络通讯层的主要职责是执行网络上的I/O的操作，支持多种网络协议（http，https等）和I/O模型的连接操作，当网络数据读取到内核缓冲区后会触发各种网络事件，这些事件会分发给事件调度层进行处理

网络通讯层的核心组件包含**BootStrap、ServerBootStrap，Channel三个组件**

#### BootStrap &ServerBootStrap

BootStrap主要是<font color=ffff>负责Netty的程序的启动，初始化，服务器连接等过程，相当于一条主线串联看Netty的其他核心组件</font>

Netty的引导器主要两种类型：

1. 用于客户端引导的BootStrap
2. 用于服务器端的ServerBootStrap

![BootStrap关系](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050134461.png)

<font color=gren>BootStrap可以用于连接远端服务器上，只会绑定一个EventLoopGroup</font>

<font color=red>ServerBootStrap用于服务器端的启动绑定本地的端口，会绑定两个EventLoopGroup，这两个EventLoopGroup通常称为Boss和Worker。Boss主要是不停的接收远端的连接，之后会将这些连接分配给worker处理器进行相关的业务处理</font>

#### Channel

Channel提供了基本的 API 用于网络 I/O 操作，如 register、bind、connect、read、write、flush 等。Netty 自己实现的 Channel 是以 JDK NIO Channel 为基础的，相比较于 JDK NIO，Netty 的 Channel 提供了更高层次的抽象，同时屏蔽了底层 Socket 的复杂性，赋予了 Channel 更加强大的功能

![channel继承关系](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050135528.png)

当然 Channel 会有多种状态，如**连接建立、连接注册、数据读写、连接销毁**等。随着状态的变化，Channel 处于不同的生命周期，每一种状态都会绑定相应的事件回调

| 事件                | 说明                                          |
| :------------------ | :-------------------------------------------- |
| channelRegistered   | Channel 创建后被注册到 EventLoop 上           |
| channelUnregistered | Channel 创建后未注册或者从 EventLoop 取消注册 |
| channelActive       | Channel 处于就绪状态，可以被读写              |
| channelInactive     | Channel 处于非就绪状态                        |
| channelRead         | Channel 可以从远端读取到数据                  |
| channelReadComplete | Channel 读取数据完成                          |

### 事件调度层

事件调度层的职责主要是通过Reactor线程模型对各类事件进行聚合处理，通过Selector主循环线程集成多种事件（I/O事件，定时事件等），实际的业务处理主要是交给**服务编排层**相关的Handler为完成

事件调度层的核心组件<font color=ffff>EventLoopGroup和EventLoop</font>

####  EventLoopGroup 、EventLoop、Channel的关系

1. 一个EventLoopGroup会保函多个EventLoop。EventLoop用于处理Channel生命周期的的所有 I/O 事件，如 accept、connect、read、write 等 I/O 事件。
2. <font color=gren>EventLoop在同一时间内只会对应一个Channel，每个 EventLoop 负责处理多个 Channel。</font>
3. 每新建一个 Channel，**EventLoopGroup 会选择一个 EventLoop 与其绑定。该 Channel 在生命周期内都可以对 EventLoop 进行多次绑定和解绑。**

![EventLoopGroup继承关系](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050135768.png)

EventLoopGroup 的实现类是 NioEventLoopGroup，NioEventLoopGroup 也是 Netty 中最被推荐使用的线程模型。NioEventLoopGroup 继承于 MultithreadEventLoopGroup，是基于 NIO 模型开发的，可以把 NioEventLoopGroup 理解为一个线程池，每个线程负责处理多个 Channel，而同一个 Channel 只会对应一个线程。Netty 通过创建不同的 EventLoopGroup 参数配置，就可以支持 Reactor 的三种线程模型：

1. **单线程模型**：EventLoopGroup 只包含一个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup；
2. **多线程模型**：EventLoopGroup 包含多个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup；
3. **主从多线程模型**：EventLoopGroup 包含多个 EventLoop，Boss 是主 Reactor，Worker 是从 Reactor，它们分别使用不同的 EventLoopGroup，主 Reactor 负责新的网络连接 Channel 创建，然后把 Channel 注册到从 Reactor。

### 服务编排层

服务编排层的职责是负责组装各类服务，它是 Netty 的核心处理链，用以实现网络事件的动态编排和有序传播。

服务编排层的**核心组件**包括 **ChannelPipeline**、**ChannelHandler、ChannelHandlerContext**。

#### ChannelPipeline

ChannelPipeline 是 Netty 的核心编排组件，**负责组装各种 ChannelHandler**，实际数据的编解码以及加工处理操作都是由 ChannelHandler 完成的。ChannelPipeline 可以理解为**ChannelHandler 的实例列表**——内部通过双向链表将不同的 ChannelHandler 链接在一起。当 I/O 读写事件触发时，ChannelPipeline 会依次调用 ChannelHandler 列表对 Channel 的数据进行拦截和处理。

ChannelPipeline 是线程安全的，因为每一个新的 Channel 都会对应绑定一个新的 ChannelPipeline。一个 ChannelPipeline 关联一个 EventLoop，一个 EventLoop 仅会绑定一个线程。

ChannelPipeline、ChannelHandler 都是高度可定制的组件。开发者可以通过这两个核心组件掌握对 Channel 数据操作的控制权。下面我们看一下 ChannelPipeline 的结构图：

![ChannelPipeline 的结构图](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050135738.png)

ChannelPipeline 中包含入站 ChannelInboundHandler 和出站 ChannelOutboundHandler 两种处理器，我们结合客户端和服务端的数据收发流程来理解 Netty 的这两个概念。

客户端和服务端都有各自的 ChannelPipeline。**以客户端为例**，数据从客户端发向服务端，该过程称为**出站**，反之则称为**入站**。数据入站会由一系列 InBoundHandler 处理，然后再以相反方向的 OutBoundHandler 处理后完成出站。我们经常使用的编码 Encoder 是出站操作，解码 Decoder 是入站操作。服务端接收到客户端数据后，需要先经过 Decoder 入站处理后，再通过 Encoder 出站通知客户端。所以客户端和服务端一次完整的请求应答过程可以分为三个步骤：客户端出站（请求数据）、服务端入站（解析数据并执行业务逻辑）、服务端出站（响应结果）。

#### ChannelHandler & ChannelHandlerContext

数据的编解码工作以及其他转换工作实际都是通过 ChannelHandler 处理的。站在开发者的角度，最需要关注的就是 ChannelHandler，我们很少会直接操作 Channel，都是通过 ChannelHandler 间接完成

每创建一个 Channel 都会绑定一个新的 ChannelPipeline，ChannelPipeline 中每加入一个 ChannelHandler 都会绑定一个 ChannelHandlerContext。由此可见，ChannelPipeline、ChannelHandlerContext、ChannelHandler 三个组件的关系是密切相关的

**每个 ChannelHandler 绑定ChannelHandlerContext 的作用**：ChannelHandlerContext 用于保存 ChannelHandler 上下文，通过 ChannelHandlerContext 可以知道 ChannelPipeline 和 ChannelHandler 的关联关系。ChannelHandlerContext 可以实现 ChannelHandler 之间的交互，ChannelHandlerContext 包含了 ChannelHandler 生命周期的所有事件，如 connect、bind、read、flush、write、close 等
