



# 安装环境

1. 系统：CentOS 7
2. Java环境： JDK8

# 下载及安装

　Zookeeper有单机、伪集群、集群三种部署方式，我使用的Zookeeper版本是：Zookeeper-3.5.9

下载Zookeeper

```sh
wget https://apache.claz.org/Zookeeper/Zookeeper-3.5.9/apache-Zookeeper-3.5.9-bin.tar.gz
```

## 单机模式

### 解压

```sh
//解压到指定目录
tar -zxvf apache-Zookeeper-3.5.9-bin.tar.gz   -C /user/soft/
```

解压后目录

![image-20210301110435970](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050038768.png)

进入conf目录，创建一个Zookeeper的配置文件zoo.cfg，可复制conf/zoo_sample.cfg作为配置文件

```sh
cd conf
cp zoo_sample.cfg zoo.cfg
```

### 配置文件说明：

```sh
# The number of milliseconds of each tick
# tickTime：CS通信心跳数
# Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。
tickTime=2000

# The number of ticks that the initial 
# synchronization phase can take
#initLimit：LF初始通信时限
# 集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。
initLimit=10

# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
# syncLimit：LF同步通信时限
# 集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime*syncLimit ）。
syncLimit=5

# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
# dataDir：数据文件目录
# Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。
dataDir=/usr/soft/Zookeeper/apache-Zookeeper-3.6.2-bin/data

# the port at which the clients will connect
#clientPort：客户端连接端口
#客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。
clientPort=2181

# the maximum number of client connections.
# increase this if you need to handle more clients
#最大连接数
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# http://Zookeeper.apache.org/doc/current/ZookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#保留数量3
#autopurge.snapRetainCount=3

# Purge task interval in hours
# Set to "0" to disable auto purge feature
#清理时间间隔1小时
#autopurge.purgeInterval=1

## Metrics Providers
#
# https://prometheus.io Metrics Exporter
#metricsProvider.className=org.apache.Zookeeper.metrics.prometheus.PrometheusMetricsProvider
#metricsProvider.httpPort=7000
#metricsProvider.exportJvmInfo=true

 # 服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口）
# 这个配置项的书写格式比较特殊，规则如下：
# server.N=YYY:A:B   
# 其中N表示服务器编号，YYY表示服务器的IP地址，A为LF通信端口，表示该服务器与集群中的leader交换的信息的端口。B为选举端口，表示选举新leader时服务器间相互通信的端口（当leader挂掉时，其余服务器会相互通信，选择出新的leader）。一般来说，集群中每个服务器的A端口都是一样，每个服务器的B端口也是一样。但是当所采用的为伪集群时，IP地址都一样，只能时A端口和B端口不一样。 

```

### 启动及停止服务

可以不修改zoo.cfg，默认配置就行，进去Zookeeper安装目录，启动Zookeeper

```sh
#启动命令：
./bin/zkServer.sh start
#在前端启动，可看启动日志
./bin/zkServer.sh start-foreground
#停止命令：
./bin/zkServer.sh stop　　

#重启命令：
./bin/zkServer.sh restart

#状态查看命令：
./bin/zkServer.sh status
```

##   伪集群模式

### 安装

在同一台主机上，通过复制得到三个Zookeeper实例

```sh
cp -r  /usr/soft/Zookeeper/Zookeeper   /usr/soft/Zookeeper/Zookeeper2
```



### 节点配置

Zookeeper1配置文件conf/zoo.cfg修改如下：

```
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/usr/soft/Zookeeper/Zookeeper1/data
dataLogDir=/usr/soft/Zookeeper/Zookeeper1/logs
clientPort=12181

server.1=127.0.0.1:12888:13888
server.2=127.0.0.1:14888:15888
server.3=127.0.0.1:16888:17888
```

注：server.1中的数字1为**服务器的ID**，需要与**myid文件中的id一致**，下一步将配置myid

Zookeeper1的data/myid配置，使用如下命令（即新建一个文件data/myid，在其中添加内容为：1）：

```sh
echo '1' > data/myid
```

Zookeeper2配置文件conf/zoo.cfg修改如下：

```
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/usr/soft/Zookeeper/Zookeeper2/data
dataLogDir=/usr/soft/Zookeeper/Zookeeper2/logs
clientPort=12182

server.1=127.0.0.1:12888:13888
server.2=127.0.0.1:14888:15888
server.3=127.0.0.1:16888:17888
```

Zookeeper2的data/myid配置，使用如下命令：

```
echo '2' > data/myid
```

Zookeeper3配置文件conf/zoo.cfg修改如下：

```
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/usr/soft/Zookeeper/Zookeeper3/data
dataLogDir=/usr/soft/Zookeeper/Zookeeper3/logs
clientPort=12183

server.1=127.0.0.1:12888:13888
server.2=127.0.0.1:14888:15888
server.3=127.0.0.1:16888:17888
```

Zookeeper3的data/myid配置，使用如下命令：

```
 echo '3' > data/myid
```

分别启动三个Zookeeper节点

![image-20210301134558405](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050038144.png)

![image-20210301134626147](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050038897.png)

![image-20210301134728171](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050038099.png)

## 集群模式

参考伪集群模式

　　　　1、在三台机器上分别部署1个Zookeeper实例

　　　　2、Zookeeper配置文件conf/zoo.cfg，如下：

```
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/usr/soft/Zookeeper/Zookeeper1/data
dataLogDir=/usr/soft/Zookeeper/Zookeeper1/logs
clientPort=12181

server.1=127.0.0.1:12888:13888
//修改为2，3节点的ip
server.2=127.0.0.1:14888:15888
server.3=127.0.0.1:16888:17888
```

3、Zookeeper的data/myid配置，使用如下命令：

```
1 echo '1' > data/myid
```

Zookeeper1 对应的是 1，Zookeeper2 对应的是 2，Zookeeper3 对应的是 3

　　4、分别启动三个Zookeeper节点，即完成对Zookeeper集群的安装

# Zookeeper简单操作

a、使用客户端连接Zookeeper服务

　命令：`./bin/zkCli.sh -server 127.0.0.1:12181`

![image-20210301140944047](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050038257.png)

b、使用 ls 命令来查看当前 Zookeeper 中所包含的内容：
命令：<font color=blue>ls /</font>

![image-20210301141124292](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050039230.png)

c 、创建节点

命令 ：<font color=blue>create /zk myData</font>

![image-20210301141402229](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050039388.png)

d、获取节点‘zk’

命令：<font color=blue>get /zk</font>

![image-20210301141449291](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050039150.png)

e、删除znode节点“ zk 

命令：<font color=blue>delete /zk</font>

![image-20210301141725018](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050039038.png)

f、退出客户端

命令：<font color=blue>quit</font>

