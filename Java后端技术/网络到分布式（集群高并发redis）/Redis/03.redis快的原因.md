# Liunx的IO

# BIO

在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：

当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。
所以，blocking IO的特点就是在IO执行的两个阶段都被block了。



![image-20210303092341779](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050034604.png)

# non-blocking IO

linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：

![image-20210303093047688](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050035513.png)

![image-20210303092823060](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050035505.png)

从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。
所以，用户进程其实是需要不断的主动询问kernel数据好了没有。

# 多路复用NIO

![image-20210303093109692](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050035127.png)

### Liunx的IO演变

![image-20210303093222430](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050035667.png)

# Redis中IO

![image-20210303102906808](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050035210.png)