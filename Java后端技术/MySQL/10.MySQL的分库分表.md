

## 分库分表前的问题

任何问题都是太大或者太小的问题，我们这里面对的数据量太大的问题。

### 用户请求量太大

因为单服务器TPS，内存，IO都是有限的。 

**解决方法**：分散请求到多个服务器上； 其实用户请求和执行一个sql查询是本质是一样的，都是请求一个资源，只是用户请求还会经过网关，路由，http服务器等。

### 单库太大

单个数据库处理能力有限；单库所在服务器上磁盘空间不足；单库上操作的IO瓶颈 

**解决方法**：切分成更多更小的库

### 单表太大

CRUD都成问题；索引膨胀，查询超时

 **解决方法**：切分成多个数据集更小的表。将表中大字段单独存放在一张表中，不常用字段放在一张表中

## 分库分表的方式方法

一般就是垂直切分和水平切分，这是一种结果集描述的切分方式，是物理空间上的切分。 我们从面临的问题，开始解决，阐述： 首先是用户请求量太大，我们就堆机器搞定（这不是本文重点）。然后是单个库太大，这时我们要看是因为表多而导致数据多，还是因为**单张表里面的数据多**。 如果是因为表多而数据多，使用**垂直切分**，根据业务切分成不同的库。如果是**因为单张表的数据量太大**，这时要用**水平切分**，即把表的数据按某种规则切分成多张表，甚至多个库上的多张表。 

**分库分表的顺序应该是先垂直分，后水平分。** 因为垂直分更简单，更符合我们处理现实世界问题的方式。

### 垂直拆分

1. 垂直分表

	就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题

2. 垂直分库

	垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上。在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。

### 水平拆分

1. 水平分表

	针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。

2. 水平分库分表

	将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

3. 水平分库分表切分规则

	- RANGE：从0到10000一个表，10001到20000一个表；
	- HASH取模：一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。
	- 地理区域：比如按照华东，华南，华北这样来区分业务
	- 时间：按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。

## 分库分表后面临的问题

### 跨节点 JOIN

在数据切分之前，关联查询可以直接通过 SQL JOIN 来完成，但是切分之后，数据可能分布在不同的节点上，此时进行关联查询就比较复杂了，一般应该尽量避免关联查询。

> 在互联网业务系统中，本来在一开始就应该避免关联查询，如果存在关联查询，有很大的可能是因为设计的不够合理或者技术选型有误。报表类的系统在 BI 时代都是通过 OLAP、数据仓库等来实现的（现在更多的借助于离线分析、流式计算等），而不应该在数据库中直接执行大量的 JOIN 查询来进行统计和分析。

**在无法避免跨节点 JOIN 操作时，一般普遍的做法是将查询分为两次，在第一次查询时找出关联数据的 ID，然后根据这些 ID 发起第二次查询得到关联数据。**

### 跨节点分页排序

一般情况下，分页都需要对数据进行排序。当排序字段就是分片字段时，通过分片规则我们可以比较容易地定位到具体的分片上，而当排序字段不是分片字段的时候，就需要在不同的分片中分别将数据进行排序，然后把结果集进行汇总并再次进行排序。

![](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050132514.png)

![](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050132110.png)

### 跨节点排序、分组和聚合操作

与跨节点分页排序类似，多数的 sharding 组件都不会对这些操作（order by、group by、count、avg 等）自动进行合并，需要手工在各个节点上得到结果集，然后在应用中进行合并，内存消耗严重。

### 分布式事务

进行了分库分表以后，原先一次业务中的事务可能会涉及到多个数据库节点。举例来说，假如有一项消费业务，在用户选购完商品进行结算时，需要扣减用户余额，用户的积分和优惠券，而用户的积分和优惠券信息可能位于其他节点的数据库中，此时我们需要保证在结算时同时扣除余额、积分和优惠券，这一系列动作需要作为一个整体，也就是一个事务进行，这个事务就是分布式事务。

分布式事务常见的解决方案有：基于 XA 的 2PC（两阶段提交），以及 2PC 的改进版本 3PC、TCC（Try-Confirm-Cancel，事务补偿），性能出色的 Best Efforts 1PC 和基于消息队列的最终一致性方案等。

由于基于 XA 的标准分布式事务过于严格，在提交事务时需要多个节点之间进行协调，很大程度上延长了事务的执行时间，这会导致访问共享资源时发生冲突和死锁的概率增大，并且这种趋势会随着节点的增多而越发明显，从而成为系统在数据库层面上进行水平伸缩的枷锁，这也是很多 sharding 系统不使用标准分布式事务的原因。与之相对的，Best Efforts 1PC 具有出色的性能优势，同时实现的方式也比较简单，因此被大多数 sharding 系统所采用。

### 主键

当数据库被切分到多个节点上时，我们就不能再以来数据库自身的主键生成机制了，因为我们无法保证某个分片上的数据库生成的 ID 在全局上是唯一的，同时我们的应用在插入数据前需要先获取 ID，以便进行 SQL 的路由

#### UUID

常见的全局唯一主键生成方案中，UUID 是最简单的一个。标准的 UUID 包含 32 个 16 进制数字，以 `8-4-4-4-12` 的形式分为五段，比如：`550e8400-e29b-41d4-a716-446655440000`，目前业界共有五种生成 UUID 的方式，详情请见 IETF 发布的 UUID 规范：[A Universally Unique IDentifier (UUID) URN Namespace](https://www.ietf.org/rfc/rfc4122.txt)。UUID 的优点是通过本地生成，没有网络消耗，性能非常高，缺点是长度过长不容易存储，且可能存在信息安全问题（基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露）。MySQL 官方对于主键的建议是越短越好，UUID 不符合要求，同时在 InnoDB 引擎中，UUID 的无序性可能会引起数据位置的频繁变动，严重影响性能。

#### sequence 表

通过数据库维护一个 sequence 表，表结构类似于：

```sql
CREATE TABLE `SEQUENCE` (
    `table_name` varchar(18) NOT NULL,
    `next_id` bigint(20) NOT NULL,
    PRIMARY KEY (`table_name`)
) ENGINE=InnoDB

```

当需要为某个表生成 ID 时，就从 sequence 表中取出对应表的 next_id，并将 next_id 的值增加 1 后更新到数据库中以备下次使用。这个方案实现简单，但是**缺点也很明显，因为所有的插入操作都需要访问这张表，因此该表很容易成为性能瓶颈，同时它也存在单点问题。**

#### snowflake

snowflake 是 twitter 的分布式自增 ID 算法，又称雪花算法。这种算法的好处是整个 ID 是趋势递增的，性能很高也很灵活，但是由于强依赖机器的时钟，**如果机器上的时钟回拨，会导致重复发号的问题**。

还有一些是在雪花算法的基础上做了优化，比如百度的 [uid-generator](https://github.com/baidu/uid-generator) 和美团的 [Leaf](https://github.com/Meituan-Dianping/Leaf)。

### 数据迁移、扩容等问题

由于扩容后路由规则发生变化，扩容前的数据行很有可能需要进行数据迁移。在进行数据迁移时，一般是不允许停机的，因此理想的扩容方式就是避免数据迁移。

## 中间件

目前分库分表的中间件主要分为两大类，一类是客户端架构，一类是代理架构。

客户端架构的中间件需要在应用中进行整合，中间件一般会以 jar 包的形式提供。通过修改应用的数据访问层（JDBC 或者以 JDBC 为基础的 ORM 框架）的方式对应用内产生的 SQL 进行解析、重写、路由、执行，并对结果集进行归并。这种架构的优点是无需对业务进行改造，简单且成本较低，但是缺点是中间件与应用绑定，对应用有一定的侵入性，不支持复杂的需求，并且对应用数据访问层的实现有限制。比较有代表性的产品为 [ShardingSphere](https://github.com/apache/incubator-shardingsphere) 。

![](https://raw.githubusercontent.com/CNRF/noteImage/main/image/202302050132791.png)

代理架构的中间件一般是一个独立的服务，相当于实现了一个支持对应数据库协议的代理服务器。以 MySQL 为例，用户可以使用 MySQL 客户端工具或者命令行访问该中间件，中间件会使用 MySQL 协议与多个 MySQL 数据库服务器进行通信。这种架构的优点是能够处理非常复杂的需求，对应用数据访问层的实现没有限制，对于应用服务透明不会增加任何额外的负载，但是缺点是由于需要独立部署，增加了运维成本，同时应用需要经过一层代理才可以访问数据库，在网络上多了一跳，影响性能并可能会有额外的风险。比较有代表性的产品有 [MyCat](https://github.com/MyCATApache/Mycat-Server) 和 [Cobar](https://github.com/alibaba/cobar)。